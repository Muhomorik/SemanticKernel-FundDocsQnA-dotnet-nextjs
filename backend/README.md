# Backend API - PDF Q&A Application

> Part of [PDF Q&A Application](../README.md). See root README for [deployment](../docs/AZURE-DEPLOYMENT.md) and [secrets management](../docs/SECRETS-MANAGEMENT.md).

ASP.NET Core Web API backend that provides semantic search and question answering capabilities for PDF documents using Semantic Kernel, OpenAI embeddings, and Groq LLM.

## Overview

This backend API loads pre-generated embeddings from the Preprocessor, stores them in an in-memory vector store, and provides endpoints to search and answer questions about your PDF documents.

## Architecture

```plaintext
Request Flow:
1. POST /api/ask with question
2. Generate embedding for question (OpenAI)
3. Search for similar chunks in memory store
4. Build context from top K results
5. Send context + question to Groq LLM
6. Return answer + source references
```

## Prerequisites

### Required

- **.NET 9 SDK** - Download from [dotnet.microsoft.com](https://dotnet.microsoft.com/download)
- **OpenAI API Key** - For generating query embeddings
  - Sign up at [platform.openai.com](https://platform.openai.com)
  - Create an API key in the dashboard
  - **Important:** Use the same model as the Preprocessor for vector space compatibility
- **Groq API Key** - Free tier for LLM
  - Sign up at [console.groq.com](https://console.groq.com)
  - Create an API key in the dashboard
- **embeddings.json** - Generated by the Preprocessor
  - Copy from Preprocessor output to `backend/Backend.API/Data/embeddings.json`

## Setup Instructions

### 1. Clone and Navigate

```bash
cd backend
```

### 2. Configure Settings

#### Option A: User Secrets (Recommended for Local Development)

Use .NET User Secrets to store API keys securely (not committed to Git):

```bash
cd Backend.API
dotnet user-secrets set "BackendOptions:GroqApiKey" "your-groq-api-key"
dotnet user-secrets set "BackendOptions:OpenAIApiKey" "your-openai-api-key"
```

See [docs/SECRETS-MANAGEMENT.md](docs/SECRETS-MANAGEMENT.md) for details.

#### Option B: Environment Variables

```bash
# Windows (PowerShell)
$env:GROQ_API_KEY="your-groq-api-key"
$env:OPENAI_API_KEY="your-openai-api-key"
$env:EMBEDDINGS_PATH="path/to/your/embeddings.json"

# Linux/macOS
export GROQ_API_KEY="your-groq-api-key"
export OPENAI_API_KEY="your-openai-api-key"
export EMBEDDINGS_PATH="path/to/your/embeddings.json"
```

### 3. Copy Embeddings File

**Important:** Ensure embeddings were generated using OpenAI (not Ollama) for vector space compatibility.

```bash
# Copy from Preprocessor output
cp ../Preprocessor/Preprocessor/bin/Debug/net9.0/output.json Backend.API/Data/embeddings.json
```

### 4. Run the Backend

```bash
cd Backend.API
dotnet run
```

The API will start at:

- HTTP: `http://localhost:5000`
- HTTPS: `https://localhost:5001`
- Swagger UI: `http://localhost:5000/swagger`
- Health (Live): `http://localhost:5000/health/live`
- Health (Ready): `http://localhost:5000/health/ready`

## Configuration Options

All configuration is in `appsettings.json` under the `BackendOptions` section:

| Setting | Default | Description |
|---------|---------|-------------|
| `EmbeddingsFilePath` | `Data/embeddings.json` | Path to embeddings JSON file |
| `GroqApiKey` | `""` | Groq API key (override via env var) |
| `GroqModel` | `llama-3.3-70b-versatile` | Groq LLM model to use |
| `GroqApiUrl` | `https://api.groq.com/openai/v1` | Groq API endpoint |
| `OpenAIApiKey` | `""` | OpenAI API key (override via env var) |
| `OpenAIEmbeddingModel` | `text-embedding-3-small` | OpenAI embedding model |
| `MaxSearchResults` | `10` | Number of chunks to retrieve |
| `MemoryCollectionName` | `fund-documents` | Memory store collection name |

## API Endpoints

### POST /api/ask

Ask a question about your PDF documents.

**Request:**

```bash
curl -X POST http://localhost:5000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"question":"What is the risk level of Spiltan Globalfond?"}'
```

**Request Body:**

```json
{
  "question": "What is the risk level of Spiltan Globalfond?"
}
```

**Response:**

```json
{
  "answer": "The fund is classified as risk level 4 out of 7, indicating moderate risk.",
  "sources": [
    {
      "file": "Spiltan_Globalfond.pdf",
      "page": 1
    }
  ]
}
```

**Status Codes:**

- `200 OK` - Success
- `400 Bad Request` - Invalid question (empty or too short)
- `500 Internal Server Error` - Processing error

### GET /health/live

Liveness probe - checks if the application is running.

**Request:**

```bash
curl http://localhost:5000/health/live
```

**Response:**

```plaintext
Healthy
```

**Status Codes:**

- `200 OK` - Application is running
- `503 Service Unavailable` - Application is not responding

### GET /health/ready

Readiness probe - checks if the application is ready to serve traffic.

**Request:**

```bash
curl http://localhost:5000/health/ready
```

**Response:**

```plaintext
Healthy
```

**Status Codes:**

- `200 OK` - Application is ready (embeddings loaded, dependencies available)
- `503 Service Unavailable` - Application is not ready

## Testing

### Manual Testing

1. **Start all dependencies:**

```bash
# Terminal 1: Start Ollama
ollama serve

# Terminal 2: Start Backend
cd backend/Backend.API
dotnet run
```

1. **Test health endpoint:**

```bash
curl http://localhost:5000/api/health
```

Expected: `{"status":"Healthy","embeddingsLoaded":true,"embeddingCount":...}`

1. **Test ask endpoint:**

```bash
curl -X POST http://localhost:5000/api/ask \
  -H "Content-Type: application/json" \
  -d '{"question":"What are the key characteristics of the funds?"}'
```

### Run Unit Tests

```bash
cd Backend.Tests
dotnet test
```

## Troubleshooting

### Issue: "Failed to initialize memory service"

**Causes:**

1. Embeddings file doesn't exist
2. Ollama is not running
3. Embedding model not available in Ollama

**Solutions:**

```bash
# Check embeddings file exists
ls Backend.API/Data/embeddings.json

# Start Ollama
ollama serve

# Pull embedding model
ollama pull nomic-embed-text

# Verify Ollama is running
curl http://localhost:11434/api/tags
```

### Issue: "Groq API key is not set"

**Solution:**

```bash
# Set environment variable
export GROQ_API_KEY="your-key-here"

# Or update appsettings.Development.json
```

### Issue: "Connection refused" when calling Ollama

**Solution:**

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# If not running, start it
ollama serve
```

### Issue: "Model 'nomic-embed-text' not found"

**Solution:**

```bash
# Pull the model
ollama pull nomic-embed-text

# Verify it's available
ollama list
```

### Issue: CORS errors from frontend

**Solution:**

Update `Program.cs` to include your frontend URL:

```csharp
policy.WithOrigins("http://localhost:3000", "https://your-frontend-url.com")
```

## Development

### Project Structure

```plaintext
Backend.API/
├── Configuration/
│   └── BackendOptions.cs          # Configuration model
├── Controllers/
│   ├── AskController.cs            # POST /api/ask
│   └── HealthController.cs         # GET /api/health
├── Models/
│   ├── EmbeddingRecord.cs          # Matches Preprocessor output
│   ├── AskRequest.cs               # API request models
│   ├── AskResponse.cs
│   ├── SourceReference.cs
│   └── HealthResponse.cs
├── Services/
│   ├── IMemoryService.cs
│   ├── MemoryService.cs            # Loads and searches embeddings
│   ├── IQuestionAnsweringService.cs
│   └── QuestionAnsweringService.cs # Orchestrates Q&A flow
├── Data/
│   └── embeddings.json             # Copy from Preprocessor
├── Program.cs                      # App startup and DI
└── appsettings.json                # Configuration
```

### Adding More Documents

When you add new PDFs using the Preprocessor:

1. Run Preprocessor with `--append` flag
2. Copy updated `embeddings.json` to backend
3. Restart the backend

```bash
# 1. In Preprocessor
cd ../Preprocessor/Preprocessor
dotnet run -- -m pdfpig -i ./pdfs -o ./bin/Debug/net9.0/output.json --append

# 2. Copy to backend
cp bin/Debug/net9.0/output.json ../../backend/Backend.API/Data/embeddings.json

# 3. Restart backend
cd ../../backend/Backend.API
dotnet run
```

## Tech Stack

- **ASP.NET Core 9** - Web API framework
- **Semantic Kernel 1.68.0** - AI orchestration
- **OpenAI** - Query embeddings (text-embedding-3-small)
- **Groq** - Cloud LLM (llama-3.3-70b-versatile, free tier)
- **Azure Application Insights** - Monitoring and telemetry (free tier)
- **Azure Key Vault** - Secrets management (production)

## Documentation

- **[Azure Deployment Guide](../docs/AZURE-DEPLOYMENT.md)** - Complete guide for deploying to Azure App Service
- **[Secrets Management Guide](../docs/SECRETS-MANAGEMENT.md)** - How to manage API keys and secrets securely
- **[Project Status](../Status.md)** - Overall project progress and implementation status
